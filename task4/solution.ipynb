{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Task 4\n","This serves as a template which will guide you through the implementation of this task. It is advised to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n","This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`."]},{"cell_type":"markdown","metadata":{},"source":["First, we import necessary libraries:"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-05-12T16:32:49.218781Z","iopub.status.busy":"2024-05-12T16:32:49.217906Z","iopub.status.idle":"2024-05-12T16:32:49.224786Z","shell.execute_reply":"2024-05-12T16:32:49.223788Z","shell.execute_reply.started":"2024-05-12T16:32:49.218747Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Add any other imports you need here\n","from transformers import AlbertTokenizer, AlbertModel\n","from pathlib import Path\n","import torch.nn.functional as F\n","\n","# Set random seeds for reproducibility\n","rseed = 42\n","torch.manual_seed(rseed)\n","np.random.seed(rseed)\n","torch.cuda.manual_seed_all(rseed)"]},{"cell_type":"markdown","metadata":{},"source":["Depending on your approach, you might need to adapt the structure of this template or parts not marked by TODOs.\n","It is not necessary to completely follow this template. Feel free to add more code and delete any parts that are not required."]},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-05-12T16:32:49.270355Z","iopub.status.busy":"2024-05-12T16:32:49.269716Z","iopub.status.idle":"2024-05-12T16:32:49.354746Z","shell.execute_reply":"2024-05-12T16:32:49.353676Z","shell.execute_reply.started":"2024-05-12T16:32:49.270323Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)\n","\n","BATCH_SIZE = 256  # TODO: Set the batch size according to both training performance and available memory\n","NUM_EPOCHS = 100  # TODO: Set the number of epochs\n","\n","train_val = pd.read_csv(\"train.csv\")\n","test_val = pd.read_csv(\"test_no_score.csv\")"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-05-12T16:32:49.356645Z","iopub.status.busy":"2024-05-12T16:32:49.356335Z","iopub.status.idle":"2024-05-12T16:32:49.371134Z","shell.execute_reply":"2024-05-12T16:32:49.370258Z","shell.execute_reply.started":"2024-05-12T16:32:49.356620Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# TODO: Fill out ReviewDataset\n","class ReviewDataset(Dataset):\n","    def __init__(self, data_frame):\n","        if \"score\" in data_frame.columns.to_list():   \n","            self.labels = data_frame[\"score\"].to_list()\n","            t_emb_path = Path('title_embeddings_train.npy')\n","            s_emb_path = Path('sentence_embeddings_train.npy')\n","        else:\n","            self.labels = None\n","            t_emb_path = Path('title_embeddings_test.npy')\n","            s_emb_path = Path('sentence_embeddings_test.npy')\n","            \n","        if t_emb_path.exists() and s_emb_path.exists():\n","            # REMINDER: delete the files if you changed the else code!!\n","            print(\"Files already exist. Loading them ...\")\n","            title_embeddings = np.load(t_emb_path)\n","            sentence_embeddings = np.load(s_emb_path)\n","        else:\n","            print(\"Files don't exist. Creating them ...\")\n","            tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n","            model = AlbertModel.from_pretrained('albert-base-v2')\n","            model = model.to(DEVICE)\n","            title_embeddings = list()\n","            sentence_embeddings = list()\n","            for t, s in zip(data_frame[\"title\"], data_frame[\"sentence\"]):\n","                title_token = tokenizer(t, return_tensors=\"pt\")\n","                title_token.to(DEVICE)\n","                sentence_token = tokenizer(s, return_tensors=\"pt\")\n","                sentence_token.to(DEVICE)\n","                with torch.no_grad():\n","                    t_emb = (model(**title_token)).pooler_output\n","                    title_embeddings.append(t_emb.reshape(t_emb.shape[0], -1).cpu().numpy())\n","                    s_emb = (model(**sentence_token)).pooler_output\n","                    sentence_embeddings.append(s_emb.reshape(s_emb.shape[0], -1).cpu().numpy())\n","            title_embeddings = np.concatenate(title_embeddings)\n","            sentence_embeddings = np.concatenate(sentence_embeddings)\n","            np.save(t_emb_path, title_embeddings)\n","            np.save(s_emb_path, sentence_embeddings)\n","            print(\"Files successfully saved!\")\n","        self.embeddings = list()\n","        for t_emb,s_emb in zip(title_embeddings, sentence_embeddings):\n","            self.embeddings.append(torch.from_numpy(np.hstack([t_emb,s_emb])))\n","            \n","    def __len__(self):\n","        return len(self.embeddings)\n","\n","    def __getitem__(self, index):\n","        if self.labels is not None:\n","            return self.embeddings[index],self.labels[index]\n","        return self.embeddings[index]"]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-05-12T16:32:49.422590Z","iopub.status.busy":"2024-05-12T16:32:49.421789Z","iopub.status.idle":"2024-05-12T16:37:54.690494Z","shell.execute_reply":"2024-05-12T16:37:54.689530Z","shell.execute_reply.started":"2024-05-12T16:32:49.422563Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Files don't exist. Creating them ...\n","Files successfully saved!\n","Files don't exist. Creating them ...\n","Files successfully saved!\n"]}],"source":["train_dataset = ReviewDataset(train_val)\n","test_dataset = ReviewDataset(test_val)\n","\n","train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=BATCH_SIZE,\n","                          shuffle=True, num_workers=1, pin_memory=True)\n","\n","test_loader = DataLoader(dataset=test_dataset,\n","                         batch_size=BATCH_SIZE,\n","                         shuffle=False, num_workers=1, pin_memory=True)\n","# Additional code if needed"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-05-12T16:37:54.692985Z","iopub.status.busy":"2024-05-12T16:37:54.692607Z","iopub.status.idle":"2024-05-12T16:37:54.710314Z","shell.execute_reply":"2024-05-12T16:37:54.709511Z","shell.execute_reply.started":"2024-05-12T16:37:54.692952Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["# TODO: Fill out MyModule\n","class MyModule(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(1536, 480)\n","        self.fc2 = nn.Linear(480, 60)\n","        self.fc3 = nn.Linear(60, 1)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = F.leaky_relu(x)\n","        x = self.fc2(x)\n","        x = F.leaky_relu(x)\n","        x = self.fc3(x)\n","        return torch.sigmoid(x) * 10\n","\n","\n","model = MyModule().to(DEVICE)"]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-05-12T16:37:54.711665Z","iopub.status.busy":"2024-05-12T16:37:54.711422Z","iopub.status.idle":"2024-05-12T16:38:22.381796Z","shell.execute_reply":"2024-05-12T16:38:22.380605Z","shell.execute_reply.started":"2024-05-12T16:37:54.711643Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 49/49 [00:00<00:00, 84.81it/s] \n","100%|██████████| 49/49 [00:00<00:00, 181.91it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.39it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.15it/s]\n","100%|██████████| 49/49 [00:00<00:00, 183.10it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.89it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.95it/s]\n","100%|██████████| 49/49 [00:00<00:00, 183.04it/s]\n","100%|██████████| 49/49 [00:00<00:00, 186.98it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.87it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.78it/s]\n","100%|██████████| 49/49 [00:00<00:00, 183.38it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.52it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.49it/s]\n","100%|██████████| 49/49 [00:00<00:00, 187.68it/s]\n","100%|██████████| 49/49 [00:00<00:00, 175.20it/s]\n","100%|██████████| 49/49 [00:00<00:00, 169.00it/s]\n","100%|██████████| 49/49 [00:00<00:00, 172.80it/s]\n","100%|██████████| 49/49 [00:00<00:00, 176.03it/s]\n","100%|██████████| 49/49 [00:00<00:00, 173.94it/s]\n","100%|██████████| 49/49 [00:00<00:00, 177.59it/s]\n","100%|██████████| 49/49 [00:00<00:00, 186.61it/s]\n","100%|██████████| 49/49 [00:00<00:00, 173.67it/s]\n","100%|██████████| 49/49 [00:00<00:00, 173.24it/s]\n","100%|██████████| 49/49 [00:00<00:00, 158.49it/s]\n","100%|██████████| 49/49 [00:00<00:00, 162.27it/s]\n","100%|██████████| 49/49 [00:00<00:00, 164.64it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.88it/s]\n","100%|██████████| 49/49 [00:00<00:00, 188.49it/s]\n","100%|██████████| 49/49 [00:00<00:00, 179.29it/s]\n","100%|██████████| 49/49 [00:00<00:00, 168.23it/s]\n","100%|██████████| 49/49 [00:00<00:00, 176.44it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.46it/s]\n","100%|██████████| 49/49 [00:00<00:00, 179.99it/s]\n","100%|██████████| 49/49 [00:00<00:00, 190.55it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.45it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.74it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.58it/s]\n","100%|██████████| 49/49 [00:00<00:00, 175.56it/s]\n","100%|██████████| 49/49 [00:00<00:00, 179.68it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.19it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.25it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.54it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.21it/s]\n","100%|██████████| 49/49 [00:00<00:00, 177.18it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.50it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.03it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.71it/s]\n","100%|██████████| 49/49 [00:00<00:00, 179.70it/s]\n","100%|██████████| 49/49 [00:00<00:00, 183.41it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.77it/s]\n","100%|██████████| 49/49 [00:00<00:00, 190.61it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.81it/s]\n","100%|██████████| 49/49 [00:00<00:00, 187.41it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.79it/s]\n","100%|██████████| 49/49 [00:00<00:00, 187.80it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.59it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.69it/s]\n","100%|██████████| 49/49 [00:00<00:00, 183.04it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.09it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.04it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.41it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.35it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.48it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.38it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.15it/s]\n","100%|██████████| 49/49 [00:00<00:00, 173.62it/s]\n","100%|██████████| 49/49 [00:00<00:00, 168.98it/s]\n","100%|██████████| 49/49 [00:00<00:00, 187.58it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.13it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.71it/s]\n","100%|██████████| 49/49 [00:00<00:00, 189.05it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.94it/s]\n","100%|██████████| 49/49 [00:00<00:00, 183.41it/s]\n","100%|██████████| 49/49 [00:00<00:00, 183.36it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.30it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.09it/s]\n","100%|██████████| 49/49 [00:00<00:00, 181.42it/s]\n","100%|██████████| 49/49 [00:00<00:00, 188.41it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.89it/s]\n","100%|██████████| 49/49 [00:00<00:00, 179.88it/s]\n","100%|██████████| 49/49 [00:00<00:00, 178.88it/s]\n","100%|██████████| 49/49 [00:00<00:00, 181.00it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.64it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.08it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.37it/s]\n","100%|██████████| 49/49 [00:00<00:00, 186.50it/s]\n","100%|██████████| 49/49 [00:00<00:00, 183.37it/s]\n","100%|██████████| 49/49 [00:00<00:00, 186.57it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.43it/s]\n","100%|██████████| 49/49 [00:00<00:00, 179.17it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.32it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.72it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.11it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.45it/s]\n","100%|██████████| 49/49 [00:00<00:00, 185.96it/s]\n","100%|██████████| 49/49 [00:00<00:00, 182.43it/s]\n","100%|██████████| 49/49 [00:00<00:00, 184.55it/s]\n","100%|██████████| 49/49 [00:00<00:00, 180.30it/s]\n","100%|██████████| 49/49 [00:00<00:00, 181.73it/s]\n"]}],"source":["# TODO: Setup loss function, optimiser, and scheduler\n","criterion = torch.nn.MSELoss()\n","optimiser = torch.optim.Adam(model.parameters(), lr=0.002)\n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimiser, gamma= 0.95)\n","model.train()\n","\n","for epoch in range(NUM_EPOCHS):\n","    # Training\n","    model.train()\n","    for batch in tqdm(train_loader, total=len(train_loader)):\n","        X, y = batch\n","        X = X.to(DEVICE)\n","        y = y.to(DEVICE)\n","        optimiser.zero_grad()\n","        outputs = model(X).squeeze()\n","        loss = criterion(outputs, y.float())\n","        loss.backward()\n","        optimiser.step()\n","        \n","    scheduler.step()\n"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2024-05-12T16:38:22.384364Z","iopub.status.busy":"2024-05-12T16:38:22.384030Z","iopub.status.idle":"2024-05-12T16:38:22.454021Z","shell.execute_reply":"2024-05-12T16:38:22.452892Z","shell.execute_reply.started":"2024-05-12T16:38:22.384335Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 4/4 [00:00<00:00, 71.25it/s]"]},{"name":"stdout","output_type":"stream","text":["Results saved!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model.eval()\n","with torch.no_grad():\n","    results = []\n","    for batch in tqdm(test_loader, total=len(test_loader)):\n","        batch = batch.to(DEVICE)\n","        results.append(model(batch).cpu().numpy().squeeze())\n"," \n","    with open(\"result.txt\", \"w\") as f:\n","        for val in np.concatenate(results):\n","            f.write(f\"{val}\\n\")\n","    print(\"Results saved!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4990360,"sourceId":8389945,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
